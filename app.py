# -*- coding: utf-8 -*-
"""
CHA ê·œì • í˜ì‹  ì–´ì‹œìŠ¤í„´íŠ¸ - Streamlit App
GPT APIë¥¼ ì‚¬ìš©í•œ ì‹¤ì œ ê·œì • ê²€ìƒ‰Â·ë¶„ì„Â·ê°œì •ì•ˆ ìƒì„± ë„êµ¬
"""

import json
import os
import re
import streamlit as st
from openai import OpenAI
from hwpml_exporter import HwpmlExporter

# ============================================================
# ì„¤ì •
# ============================================================
st.set_page_config(
    page_title="CHA ê·œì • í˜ì‹  ì–´ì‹œìŠ¤í„´íŠ¸",
    page_icon="ğŸ›ï¸",
    layout="wide",
    initial_sidebar_state="expanded",
)

# OpenAI í´ë¼ì´ì–¸íŠ¸
client = OpenAI(api_key=st.secrets.get("OPENAI_API_KEY", os.environ.get("OPENAI_API_KEY", "")))

# GPT ëª¨ë¸ ì„¤ì •
GPT_MODEL = "gpt-4o-mini"  # ë¹„ìš© íš¨ìœ¨ì . í•„ìš” ì‹œ "gpt-4o"ë¡œ ë³€ê²½


# ============================================================
# ë°ì´í„° ë¡œë“œ
# ============================================================
@st.cache_data
def load_regulations():
    """regulations.json ë¡œë“œ"""
    data_path = os.path.join(os.path.dirname(__file__), "data", "regulations.json")
    if not os.path.exists(data_path):
        st.error(f"âŒ ê·œì • ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {data_path}")
        st.info("parse_xml_to_json.pyë¥¼ ì‹¤í–‰í•˜ì—¬ data/regulations.jsonì„ ìƒì„±í•´ ì£¼ì„¸ìš”.")
        st.stop()

    with open(data_path, "r", encoding="utf-8") as f:
        return json.load(f)


@st.cache_data
def build_search_index(regulations):
    """í‚¤ì›Œë“œ ê²€ìƒ‰ìš© ì¸ë±ìŠ¤ ìƒì„±"""
    index = []
    for reg in regulations:
        entry = {
            "id": reg["id"],
            "name": reg["name"],
            "text_lower": reg["full_text"].lower(),
            "article_count": reg["article_count"],
            "char_count": reg["char_count"],
        }
        index.append(entry)
    return index


def keyword_search(query, index, regulations, top_k=10):
    """í‚¤ì›Œë“œ ê¸°ë°˜ ê·œì • ê²€ìƒ‰"""
    query_words = query.lower().split()
    results = []

    for i, entry in enumerate(index):
        score = 0
        for word in query_words:
            count = entry["text_lower"].count(word)
            if count > 0:
                score += count
                # ê·œì •ëª…ì— í¬í•¨ë˜ë©´ ê°€ì¤‘ì¹˜
                if word in entry["name"].lower():
                    score += 10

        if score > 0:
            results.append({
                "regulation": regulations[i],
                "score": score,
            })

    results.sort(key=lambda x: x["score"], reverse=True)
    return results[:top_k]


def find_relevant_articles(regulation, query):
    """íŠ¹ì • ê·œì • ë‚´ì—ì„œ ê´€ë ¨ ì¡°ë¬¸ ì°¾ê¸°"""
    query_words = query.lower().split()
    relevant = []
    for article in regulation.get("articles", []):
        content_lower = article["content"].lower()
        score = sum(content_lower.count(w) for w in query_words)
        if score > 0:
            relevant.append({**article, "score": score})

    relevant.sort(key=lambda x: x["score"], reverse=True)
    return relevant[:10]


# ============================================================
# GPT API í˜¸ì¶œ
# ============================================================
def gpt_analyze_regulations(query, search_results):
    """GPTë¡œ ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„"""
    # ê²€ìƒ‰ëœ ê·œì • ìš”ì•½ (í† í° ì ˆì•½ì„ ìœ„í•´ ì¡°ë¬¸ ì œëª©ë§Œ)
    reg_summaries = []
    for r in search_results[:5]:
        reg = r["regulation"]
        articles_summary = ", ".join(
            f'{a["number"]} ({a["title"]})'
            for a in reg.get("articles", [])[:20]
        )
        reg_summaries.append(
            f"[{reg['id']}] {reg['name']} â€” ì¡°ë¬¸: {articles_summary}"
        )

    context = "\n".join(reg_summaries)

    response = client.chat.completions.create(
        model=GPT_MODEL,
        messages=[
            {
                "role": "system",
                "content": (
                    "ë‹¹ì‹ ì€ ì°¨ì˜ê³¼í•™ëŒ€í•™êµì˜ ê·œì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤. "
                    "ëŒ€í•™ ê·œì •ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•íˆ ë‹µë³€í•˜ì„¸ìš”. "
                    "ë‹µë³€ì€ í•œêµ­ì–´ë¡œ, êµ¬ì²´ì  ì¡°ë¬¸ ë²ˆí˜¸ë¥¼ ì¸ìš©í•˜ë©° ì‘ì„±í•˜ì„¸ìš”."
                ),
            },
            {
                "role": "user",
                "content": (
                    f"ì§ˆë¬¸: {query}\n\n"
                    f"ê²€ìƒ‰ëœ ê·œì •:\n{context}\n\n"
                    f"ìœ„ ê·œì •ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ ì£¼ì„¸ìš”. "
                    f"ê´€ë ¨ ê·œì •ëª…ê³¼ ì¡°ë¬¸ ë²ˆí˜¸ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì–¸ê¸‰í•˜ê³ , "
                    f"ê°œì •ì´ í•„ìš”í•œ ë¶€ë¶„ì´ ìˆë‹¤ë©´ ì œì•ˆí•´ ì£¼ì„¸ìš”."
                ),
            },
        ],
        temperature=0.3,
        max_tokens=1500,
    )
    return response.choices[0].message.content


def gpt_draft_amendment(regulation, articles, idea):
    """GPTë¡œ ê°œì •ì•ˆ ì´ˆì•ˆ ìƒì„±"""
    # ê´€ë ¨ ì¡°ë¬¸ ì „ë¬¸ ì „ë‹¬ (í† í° ì œí•œ ê³ ë ¤í•˜ì—¬ ìƒìœ„ 5ê°œ)
    articles_text = "\n\n".join(
        f"[{a['number']} ({a['title']})]\n{a['content']}"
        for a in articles[:5]
    )

    response = client.chat.completions.create(
        model=GPT_MODEL,
        messages=[
            {
                "role": "system",
                "content": (
                    "ë‹¹ì‹ ì€ ì°¨ì˜ê³¼í•™ëŒ€í•™êµ ê·œì • ê°œì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤. "
                    "AIì¤‘ì‹¬ëŒ€í•™ ì‚¬ì—… ì¶”ì§„ì„ ìœ„í•œ ê·œì • ê°œì •ì•ˆì„ ì‘ì„±í•©ë‹ˆë‹¤. "
                    "ì‹ êµ¬ëŒ€ì¡°ë¬¸ í˜•ì‹(í˜„í–‰ â†’ ê°œì •ì•ˆ)ìœ¼ë¡œ ì‘ì„±í•˜ë˜, "
                    "ë²•ë¥  ìš©ì–´ë¥¼ ì •í™•í•˜ê²Œ ì‚¬ìš©í•˜ê³ , ë¶€ì¹™(ê²½ê³¼ê·œì •)ë„ í¬í•¨í•˜ì„¸ìš”."
                ),
            },
            {
                "role": "user",
                "content": (
                    f"ê·œì •ëª…: {regulation['name']}\n\n"
                    f"í˜ì‹  ì•„ì´ë””ì–´: {idea}\n\n"
                    f"ê´€ë ¨ í˜„í–‰ ì¡°ë¬¸:\n{articles_text}\n\n"
                    f"ìœ„ ì¡°ë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ ì‹ êµ¬ëŒ€ì¡°ë¬¸ í˜•ì‹ì˜ ê°œì •ì•ˆ ì´ˆì•ˆì„ ì‘ì„±í•´ ì£¼ì„¸ìš”.\n"
                    f"í˜•ì‹:\n"
                    f"## ì‹ êµ¬ëŒ€ì¡°ë¬¸\n"
                    f"| í˜„í–‰ | ê°œì •ì•ˆ |\n"
                    f"ê° ë³€ê²½ í•­ëª©ë³„ë¡œ ì‘ì„±í•˜ê³ , ë§ˆì§€ë§‰ì— ë¶€ì¹™(ê²½ê³¼ê·œì •)ì„ ì¶”ê°€í•˜ì„¸ìš”."
                ),
            },
        ],
        temperature=0.4,
        max_tokens=2000,
    )
    return response.choices[0].message.content


def gpt_regulation_chat(query, regulation, chat_history):
    """íŠ¹ì • ê·œì •ì— ëŒ€í•œ ììœ  ì§ˆì˜ì‘ë‹µ"""
    # ê·œì • ì „ë¬¸ì´ ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ì„œ ì „ë‹¬
    full_text = regulation["full_text"]
    if len(full_text) > 8000:
        full_text = full_text[:8000] + "\n...(ì´í•˜ ìƒëµ)"

    messages = [
        {
            "role": "system",
            "content": (
                f"ë‹¹ì‹ ì€ ì°¨ì˜ê³¼í•™ëŒ€í•™êµ '{regulation['name']}' ì „ë¬¸ê°€ì…ë‹ˆë‹¤. "
                f"ì•„ë˜ëŠ” í•´ë‹¹ ê·œì •ì˜ ì „ë¬¸ì…ë‹ˆë‹¤. ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ì •í™•íˆ ë‹µë³€í•˜ì„¸ìš”.\n\n"
                f"---\n{full_text}\n---"
            ),
        },
    ]

    # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶”ê°€
    for msg in chat_history[-6:]:  # ìµœê·¼ 6ê°œ ë©”ì‹œì§€
        messages.append(msg)

    messages.append({"role": "user", "content": query})

    response = client.chat.completions.create(
        model=GPT_MODEL,
        messages=messages,
        temperature=0.3,
        max_tokens=1500,
    )
    return response.choices[0].message.content


# ============================================================
# UI ìŠ¤íƒ€ì¼
# ============================================================
def apply_custom_css():
    st.markdown("""
    <style>
        @import url('https://cdn.jsdelivr.net/gh/orioncactus/pretendard/dist/web/static/pretendard.css');
        
        .stApp { font-family: 'Pretendard', sans-serif; }
        
        .main-header {
            background: linear-gradient(135deg, #0a3327, #0F4C3A, #1a6b4a);
            padding: 24px 32px;
            border-radius: 16px;
            margin-bottom: 24px;
            color: white;
        }
        .main-header h1 { color: white; font-size: 26px; margin: 0; }
        .main-header p { color: rgba(255,255,255,0.6); font-size: 13px; margin: 4px 0 0; }
        
        .stat-card {
            background: white;
            border: 1px solid #e8e8e8;
            border-radius: 12px;
            padding: 16px 20px;
            text-align: center;
        }
        .stat-card .number { font-size: 28px; font-weight: 800; color: #0F4C3A; }
        .stat-card .label { font-size: 12px; color: #888; margin-top: 4px; }
        
        .reg-card {
            background: white;
            border: 1px solid #e8e8e8;
            border-radius: 12px;
            padding: 16px 20px;
            margin-bottom: 10px;
            transition: all 0.2s;
        }
        .reg-card:hover { border-color: #0F4C3A; box-shadow: 0 2px 12px rgba(15,76,58,0.1); }
        
        .article-box {
            background: #f8faf9;
            border-left: 3px solid #0F4C3A;
            padding: 12px 16px;
            margin: 8px 0;
            border-radius: 0 8px 8px 0;
            font-size: 14px;
            line-height: 1.8;
        }
        
        div[data-testid="stSidebar"] {
            background: #f7faf8;
        }
    </style>
    """, unsafe_allow_html=True)


# ============================================================
# í˜ì´ì§€: ê·œì • ê²€ìƒ‰
# ============================================================
def page_search(regulations, search_index):
    st.markdown("### ğŸ” ê·œì • ê²€ìƒ‰")
    st.caption("í‚¤ì›Œë“œë¡œ 136ê°œ ê·œì •ì„ ê²€ìƒ‰í•˜ê³ , GPTê°€ ê´€ë ¨ ì¡°ë¬¸ì„ ë¶„ì„í•©ë‹ˆë‹¤.")

    query = st.text_input(
        "ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”",
        placeholder="ì˜ˆ: AI êµìœ¡ê³¼ì •, ì—°êµ¬ë¹„ ê°„ì ‘ë¹„, êµì› ì„ìš©, íœ´í•™ ë³µí•™...",
        label_visibility="collapsed",
    )

    col1, col2 = st.columns([3, 1])
    with col2:
        use_gpt = st.toggle("GPT ë¶„ì„", value=True, help="GPTë¡œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤")

    if query:
        results = keyword_search(query, search_index, regulations)

        if not results:
            st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ì‹œë„í•´ ë³´ì„¸ìš”.")
            return

        st.markdown(f"**ğŸ“ {len(results)}ê±´ì˜ ê´€ë ¨ ê·œì •**")

        # GPT ë¶„ì„
        if use_gpt and results:
            with st.spinner("ğŸ¤– GPTê°€ ê·œì •ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                try:
                    analysis = gpt_analyze_regulations(query, results)
                    with st.expander("ğŸ¤– GPT ë¶„ì„ ê²°ê³¼", expanded=True):
                        st.markdown(analysis)
                        
                        # XML ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                        exporter = HwpmlExporter()
                        reg_info = [
                            {"name": r["regulation"]["name"], 
                             "article_count": r["regulation"]["article_count"],
                             "score": r["score"]}
                            for r in results[:5]
                        ]
                        xml_bytes = exporter.create_analysis_doc(
                            title=f"ê·œì • ë¶„ì„: {query}",
                            query=query,
                            analysis_text=analysis,
                            regulations=reg_info,
                        )
                        st.download_button(
                            "ğŸ“¥ ë¶„ì„ ê²°ê³¼ XML ë‹¤ìš´ë¡œë“œ (í•œ/ê¸€ í˜¸í™˜)",
                            data=xml_bytes,
                            file_name=f"ê·œì •ë¶„ì„_{query[:20]}.xml",
                            mime="application/xml",
                        )
                except Exception as e:
                    st.error(f"GPT ë¶„ì„ ì‹¤íŒ¨: {e}")

        # ê²€ìƒ‰ ê²°ê³¼ ëª©ë¡
        for r in results:
            reg = r["regulation"]
            score = r["score"]

            with st.expander(f"ğŸ“„ {reg['name']}  (ê´€ë ¨ë„: {score}ì  Â· {reg['article_count']}ê°œ ì¡°ë¬¸)"):
                # ê´€ë ¨ ì¡°ë¬¸ í•˜ì´ë¼ì´íŠ¸
                relevant_articles = find_relevant_articles(reg, query)
                if relevant_articles:
                    st.markdown("**ê´€ë ¨ ì¡°ë¬¸:**")
                    for article in relevant_articles[:5]:
                        st.markdown(
                            f'<div class="article-box">'
                            f'<strong>{article["number"]} ({article["title"]})</strong><br/>'
                            f'{article["content"][:300]}{"..." if len(article["content"]) > 300 else ""}'
                            f'</div>',
                            unsafe_allow_html=True,
                        )
                else:
                    st.caption("ì¡°ë¬¸ ë‹¨ìœ„ íŒŒì‹± ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ê²€ìƒ‰ë˜ì—ˆìŠµë‹ˆë‹¤.")

                # ê·œì • ì „ë¬¸ ë³´ê¸°
                if st.button(f"ì „ë¬¸ ë³´ê¸°", key=f"full_{reg['id']}"):
                    st.text_area(
                        "ê·œì • ì „ë¬¸",
                        reg["full_text"],
                        height=400,
                        key=f"text_{reg['id']}",
                    )


# ============================================================
# í˜ì´ì§€: ê·œì • ê°œì • ë„ìš°ë¯¸
# ============================================================
def page_amendment(regulations, search_index):
    st.markdown("### ğŸ“ ê·œì • ê°œì • ë„ìš°ë¯¸")
    st.caption("í˜ì‹  ì•„ì´ë””ì–´ë¥¼ ì…ë ¥í•˜ë©´ ê´€ë ¨ ê·œì •ì„ ì°¾ê³  ê°œì •ì•ˆ ì´ˆì•ˆì„ GPTê°€ ìƒì„±í•©ë‹ˆë‹¤.")

    # Step 1: ì•„ì´ë””ì–´ ì…ë ¥
    idea = st.text_area(
        "í˜ì‹  ì•„ì´ë””ì–´",
        placeholder="ì˜ˆ: AI ê¸°ë°˜ ì˜ë£Œë°ì´í„° ë¶„ì„ êµìœ¡ê³¼ì •ì„ ì‹ ì„¤í•˜ì—¬ í•™ë¶€-ëŒ€í•™ì› ì—°ê³„ Fast Trackì„ ë§Œë“¤ê³  ì‹¶ìŠµë‹ˆë‹¤.",
        height=100,
    )

    example_ideas = [
        "AI ê¸°ë°˜ ì˜ë£Œë°ì´í„° êµìœ¡ê³¼ì • ì‹ ì„¤",
        "ë°”ì´ì˜¤í—¬ìŠ¤ì¼€ì–´ ì‚°í•™í˜‘ë ¥ ì¸í„´ì‹­ ë„ì…",
        "ë¹„ì „ì„êµì› AI ì—°êµ¬ ì°¸ì—¬ í™•ëŒ€",
    ]
    st.caption("ì˜ˆì‹œ: " + " Â· ".join(f"`{e}`" for e in example_ideas))

    if not idea:
        return

    # Step 2: ê´€ë ¨ ê·œì • ê²€ìƒ‰
    results = keyword_search(idea, search_index, regulations)

    if not results:
        st.warning("ê´€ë ¨ ê·œì •ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return

    st.markdown(f"**ğŸ“ ê´€ë ¨ ê·œì • {len(results)}ê±´**")

    # ê·œì • ì„ íƒ
    reg_options = {
        f"{r['regulation']['name']} (ê´€ë ¨ë„: {r['score']}ì )": i
        for i, r in enumerate(results)
    }
    selected_names = st.multiselect(
        "ê°œì • ëŒ€ìƒ ê·œì •ì„ ì„ íƒí•˜ì„¸ìš”",
        options=list(reg_options.keys()),
        default=[list(reg_options.keys())[0]] if reg_options else [],
    )

    if not selected_names:
        return

    # Step 3: ê°œì •ì•ˆ ìƒì„±
    if st.button("ğŸ“„ ê°œì •ì•ˆ ì´ˆì•ˆ ìƒì„±", type="primary", use_container_width=True):
        for name in selected_names:
            idx = reg_options[name]
            reg = results[idx]["regulation"]
            relevant_articles = find_relevant_articles(reg, idea)

            with st.spinner(f"ğŸ¤– '{reg['name']}' ê°œì •ì•ˆ ìƒì„± ì¤‘..."):
                try:
                    draft = gpt_draft_amendment(reg, relevant_articles, idea)
                    st.markdown(f"#### ğŸ“„ {reg['name']} ê°œì •ì•ˆ")
                    st.markdown(draft)
                    
                    # XML ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                    exporter = HwpmlExporter()
                    amendment_rows = exporter.parse_gpt_amendment(draft)
                    if not amendment_rows:
                        amendment_rows = [{"current": "(GPT ìƒì„± í…ìŠ¤íŠ¸)", "revised": draft}]
                    
                    metadata = {
                        "background": f"CHAëŒ€í•™êµ AIì¤‘ì‹¬ëŒ€í•™ ì‚¬ì—… ì¶”ì§„ì— ë”°ë¥¸ {reg['name']} ì •ë¹„",
                        "core_content": idea[:100],
                        "related_regs": ", ".join(n.split(" (")[0] for n in selected_names),
                        "department": reg.get("dept", ""),
                        "cooperating": "êµë¬´ì²˜, ì •ë³´ì „ì‚°ì›, ì‚°í•™í˜‘ë ¥ë‹¨",
                        "schedule": "2026.03 ~ 2026.06 (ì•½ 12ì£¼)",
                        "target": "2026ë…„ 2í•™ê¸°ë¶€í„° ì ìš©",
                    }
                    xml_bytes = exporter.create_amendment_doc(
                        title=f"{reg['name']} ê°œì •ì•ˆ",
                        amendment_rows=amendment_rows,
                        metadata=metadata,
                    )
                    st.download_button(
                        f"ğŸ“¥ {reg['name']} ê°œì •ì•ˆ XML ë‹¤ìš´ë¡œë“œ (í•œ/ê¸€ í˜¸í™˜)",
                        data=xml_bytes,
                        file_name=f"{reg['name']}_ê°œì •ì•ˆ.xml",
                        mime="application/xml",
                        key=f"dl_{reg['id']}",
                    )
                    st.divider()
                except Exception as e:
                    st.error(f"ê°œì •ì•ˆ ìƒì„± ì‹¤íŒ¨ ({reg['name']}): {e}")


# ============================================================
# í˜ì´ì§€: ê·œì • Q&A (ì±„íŒ…)
# ============================================================
def page_chat(regulations):
    st.markdown("### ğŸ’¬ ê·œì • Q&A")
    st.caption("íŠ¹ì • ê·œì •ì„ ì„ íƒí•˜ê³  ììœ ë¡­ê²Œ ì§ˆë¬¸í•˜ì„¸ìš”. GPTê°€ ê·œì • ì „ë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.")

    # ê·œì • ì„ íƒ
    reg_names = {reg["name"]: i for i, reg in enumerate(regulations)}
    selected_name = st.selectbox("ê·œì • ì„ íƒ", options=list(reg_names.keys()))

    if not selected_name:
        return

    reg = regulations[reg_names[selected_name]]
    st.caption(f"ğŸ“Š {reg['article_count']}ê°œ ì¡°ë¬¸ Â· {reg['char_count']:,}ì")

    # ì±„íŒ… íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
    chat_key = f"chat_{reg['id']}"
    if chat_key not in st.session_state:
        st.session_state[chat_key] = []

    # ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ
    for msg in st.session_state[chat_key]:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # ì§ˆë¬¸ ì…ë ¥
    if prompt := st.chat_input(f"'{selected_name}'ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”..."):
        # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
        with st.chat_message("user"):
            st.markdown(prompt)

        # GPT ì‘ë‹µ
        with st.chat_message("assistant"):
            with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                try:
                    response = gpt_regulation_chat(
                        prompt, reg, st.session_state[chat_key]
                    )
                    st.markdown(response)
                except Exception as e:
                    response = f"âŒ ì˜¤ë¥˜: {e}"
                    st.error(response)

        # íˆìŠ¤í† ë¦¬ ì €ì¥
        st.session_state[chat_key].append({"role": "user", "content": prompt})
        st.session_state[chat_key].append({"role": "assistant", "content": response})

    # Q&A ê¸°ë¡ ë‹¤ìš´ë¡œë“œ
    if st.session_state.get(chat_key):
        qa_pairs = []
        msgs = st.session_state[chat_key]
        for i in range(0, len(msgs) - 1, 2):
            if msgs[i]["role"] == "user" and msgs[i + 1]["role"] == "assistant":
                qa_pairs.append({
                    "question": msgs[i]["content"],
                    "answer": msgs[i + 1]["content"],
                })
        if qa_pairs:
            exporter = HwpmlExporter()
            xml_bytes = exporter.create_qa_doc(selected_name, qa_pairs)
            st.download_button(
                "ğŸ“¥ Q&A ê¸°ë¡ XML ë‹¤ìš´ë¡œë“œ (í•œ/ê¸€ í˜¸í™˜)",
                data=xml_bytes,
                file_name=f"{selected_name}_QAê¸°ë¡.xml",
                mime="application/xml",
            )


# ============================================================
# í˜ì´ì§€: ê·œì • í˜„í™© ëŒ€ì‹œë³´ë“œ
# ============================================================
def page_dashboard(regulations):
    st.markdown("### ğŸ“Š ê·œì • í˜„í™© ëŒ€ì‹œë³´ë“œ")

    # í†µê³„ ì¹´ë“œ
    total_regs = len(regulations)
    total_articles = sum(r["article_count"] for r in regulations)
    total_chars = sum(r["char_count"] for r in regulations)

    c1, c2, c3 = st.columns(3)
    with c1:
        st.metric("ì „ì²´ ê·œì • ìˆ˜", f"{total_regs}ê°œ")
    with c2:
        st.metric("ì´ ì¡°ë¬¸ ìˆ˜", f"{total_articles:,}ê°œ")
    with c3:
        st.metric("ì´ í…ìŠ¤íŠ¸ëŸ‰", f"{total_chars:,}ì")

    st.divider()

    # ê·œì • ëª©ë¡ í…Œì´ë¸”
    st.markdown("**ğŸ“‹ ì „ì²´ ê·œì • ëª©ë¡**")
    table_data = []
    for reg in regulations:
        table_data.append({
            "ID": reg["id"],
            "ê·œì •ëª…": reg["name"][:40],
            "ì¡°ë¬¸ ìˆ˜": reg["article_count"],
            "í…ìŠ¤íŠ¸(ì)": f"{reg['char_count']:,}",
        })

    st.dataframe(
        table_data,
        use_container_width=True,
        hide_index=True,
    )


# ============================================================
# ë©”ì¸
# ============================================================
def main():
    apply_custom_css()

    # í—¤ë”
    st.markdown(
        '<div class="main-header">'
        "<h1>ğŸ›ï¸ CHA ê·œì • í˜ì‹  ì–´ì‹œìŠ¤í„´íŠ¸</h1>"
        "<p>Regulation Innovation Assistant Â· GPT ê¸°ë°˜ ê·œì • ê²€ìƒ‰Â·ë¶„ì„Â·ê°œì • ë„êµ¬</p>"
        "</div>",
        unsafe_allow_html=True,
    )

    # API í‚¤ í™•ì¸
    if not client.api_key:
        st.error("âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.markdown(
            "Streamlit Cloud: **Settings â†’ Secrets**ì— ì•„ë˜ë¥¼ ì¶”ê°€í•˜ì„¸ìš”:\n"
            "```toml\n"
            'OPENAI_API_KEY = "sk-..."\n'
            "```"
        )
        st.stop()

    # ë°ì´í„° ë¡œë“œ
    regulations = load_regulations()
    search_index = build_search_index(regulations)

    # ì‚¬ì´ë“œë°” ë„¤ë¹„ê²Œì´ì…˜
    with st.sidebar:
        st.markdown("### ë©”ë‰´")
        page = st.radio(
            "ê¸°ëŠ¥ ì„ íƒ",
            ["ğŸ” ê·œì • ê²€ìƒ‰", "ğŸ“ ê°œì • ë„ìš°ë¯¸", "ğŸ’¬ ê·œì • Q&A", "ğŸ“Š í˜„í™© ëŒ€ì‹œë³´ë“œ"],
            label_visibility="collapsed",
        )

        st.divider()
        st.caption(f"ğŸ“ {len(regulations)}ê°œ ê·œì • ë¡œë“œë¨")
        st.caption("ğŸ¤– GPT: " + GPT_MODEL)
        st.caption("v2.0 Â· í”¼í„°(Peter) ì œì‘")

    # í˜ì´ì§€ ë¼ìš°íŒ…
    if page == "ğŸ” ê·œì • ê²€ìƒ‰":
        page_search(regulations, search_index)
    elif page == "ğŸ“ ê°œì • ë„ìš°ë¯¸":
        page_amendment(regulations, search_index)
    elif page == "ğŸ’¬ ê·œì • Q&A":
        page_chat(regulations)
    elif page == "ğŸ“Š í˜„í™© ëŒ€ì‹œë³´ë“œ":
        page_dashboard(regulations)


if __name__ == "__main__":
    main()
